# Transformers and ML libraries
transformers>=5.0.0,<5.2.0
# torch is installed separately via pip with CUDA support
# accelerate not needed since we use .to(device) approach

# FastAPI for serving
fastapi>=0.128.0,<0.129.0
uvicorn[standard]>=0.30.0,<0.33.0
pydantic>=2.9.0,<3.0.0

# Tokenizer support
sentencepiece>=0.2.0,<0.3.0
