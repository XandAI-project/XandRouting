fastapi>=0.115.0,<0.130.0
uvicorn[standard]>=0.27.0,<0.35.0
pydantic>=2.5.0,<3.0.0
httpx>=0.26.0,<0.28.0
vllm==0.8.5
transformers>=4.37.0,<5.0.0
torch>=2.4.0,<2.6.0
accelerate>=0.25.0,<0.35.0
numpy>=1.26.0,<2.0.0
sentencepiece>=0.1.99,<0.3.0
protobuf>=4.25.1,<6.0.0
llama-cpp-python>=0.2.27
huggingface-hub>=0.20.0,<1.0.0
